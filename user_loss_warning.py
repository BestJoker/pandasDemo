# coding:utf-8import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport osimport seaborn as snsimport pandas_profilingfrom sklearn.preprocessing import StandardScalerfrom sklearn.linear_model import LogisticRegression as LRimport model_test_indexfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_scorefrom sklearn.ensemble import RandomForestClassifierfrom sklearn.model_selection import GridSearchCVfrom sklearn.model_selection import cross_val_scoreimport joblibpd.options.mode.chained_assignment = None # 默认是'warn'plt.rcParams['font.sans-serif']=['Microsoft YaHei'] #用来正常显示中文标签字体。Microsoft YaHei 或 SimHeiplt.rcParams['axes.unicode_minus']=False #用来正常显示负号#获取文件地址def get_file_path(file_name):    PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))    path = os.path.join(PROJECT_ROOT, 'data/user_loss_warning/'+file_name)    return path#获取原始数据,return 处理后的x和ydef get_handle_data():    # path = get_file_path('2019-09-01用户流失预警数据.xlsx')    # orign_df = pd.read_excel(path)    paths = [get_file_path('2019-07-01用户流失预警数据.xlsx'),             get_file_path('2019-08-01用户流失预警数据.xlsx'),             get_file_path('2019-09-01用户流失预警数据.xlsx')]    total_df = pd.DataFrame()    for path in paths:        orign_df = pd.read_excel(path)        total_df = total_df.append(orign_df)    print (total_df.shape)    x,y = handle_data(total_df)    return x,y#处理数据def handle_data(orign_df):    #1.处理count异常值    df = orign_df.copy()    print (df.info())    #数据标准化    x = df.loc[:,df.columns != 'is_silence']    y = df['is_silence']    scaler = StandardScaler() #实例化    x_std = scaler.fit_transform(x) #标准化    print (x.shape,y.shape)    print (y.value_counts())    print (df['is_silence'].value_counts())    return x_std,ydef LR_m(x,y):    X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3,random_state=420)    L1 = LR(penalty='l2',solver='saga', C=0.3, max_iter=1000, class_weight='balanced')    L1 = L1.fit(X_train, Y_train)    y_predcit = L1.predict(X_test)    model_test_index.basic_data_confusion(Y_test, y_predcit)    y_predprob = L1.predict_proba(X_test)    model_test_index.auc_roc_curve(Y_test, y_predprob)    # 模型准确率: 72.44 %    # 模型精确率: 6.26 %    # 模型召回率: 85.31 %    # 模型F1值: 11.66 %    # AUC值为： 86.81 %    # KS = 0.59def base_LR(x,y):    print ('base line')    X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3,random_state=420)    L1 = LR(penalty='l1', solver='saga', C=0.05, max_iter=1000, class_weight='balanced')    L1 = L1.fit(X_train, Y_train)    y_predcit = L1.predict(X_test)    model_test_index.basic_data_confusion(Y_test, y_predcit)    y_predprob = L1.predict_proba(X_test)    model_test_index.auc_roc_curve(Y_test, y_predprob)    print ('-'*30)    # 模型准确率: 72.41 %    # 模型精确率: 6.28 %    # 模型召回率: 85.78 %    # 模型F1值: 11.71 %    # AUC值为： 86.79%    # KS = 0.59def base_RFC(x,y):    rfc = RandomForestClassifier(n_estimators=50,criterion='gini',max_depth=9,random_state=420,class_weight="balanced",n_jobs=-1)    X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3,random_state=420)    rfc = rfc.fit(X_train,Y_train)    y_predict = rfc.predict(X_test)    model_test_index.basic_data_confusion(Y_test,y_predict)    y_preprob = rfc.predict_proba(X_test)    model_test_index.auc_roc_curve(Y_test,y_preprob)    model_test_index.corss_val_score_cus(rfc,x,y,cv=5)    joblib.dump(rfc,get_file_path('rfc.pkl'))    return rfc    # 模型准确率: 85.28 %    # 模型精确率: 8.91 %    # 模型召回率: 63.98 %    # 模型F1值: 15.64 %    # AUC值为： 85.79 %    # KS = 0.57def iteration_RFC(x,y):    param_grid = {        'criterion':['gini', 'entropy'],        'max_depth' : np.arange(1, 20, 1)    }    rfc = RandomForestClassifier(random_state=420,class_weight="balanced",n_jobs=-1)    GS = GridSearchCV(rfc, param_grid, cv=10)    GS.fit(x, y)    print (GS.best_params_)    print (GS.best_score_)def load_cus_model():    print (1)    try:        model = joblib.load(get_file_path('rfc.pkl'))    except IOError:        x, y = get_handle_data()        model = base_RFC(x, y)        return model    else:        model = joblib.load(get_file_path('rfc.pkl'))        return model#主函数if __name__ == '__main__':    model = load_cus_model()    # x, y = get_handle_data()    # base_RFC(x, y)    # iteration_RFC(x, y)