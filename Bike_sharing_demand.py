# coding:utf-8import pandas as pdimport numpy as npimport osimport matplotlib.pyplot as pltimport seaborn as snsimport datetimeimport model_test_indexfrom sklearn.model_selection import GridSearchCVpd.options.mode.chained_assignment = None # 默认是'warn'plt.rcParams['font.sans-serif']=['Microsoft YaHei'] #用来正常显示中文标签字体。Microsoft YaHei 或 SimHeiplt.rcParams['axes.unicode_minus']=False #用来正常显示负号#https://zhuanlan.zhihu.com/p/41800432'''具体内容为：通过历史用车记录结合日期、天气、温湿度等等因素来预测共享单车项目在华盛顿的需求datetime(时间) - hourly date + timestampseason(季节) - 1 = spring, 2 = summer, 3 = fall, 4 = winterholiday(是否节日) - whether the day is considered a holidayworkingday(是否工作日) - whether the day is neither a weekend nor holidayweather(天气) -1: Clear, Few clouds, Partly cloudy, Partly cloudy清澈，少云，多云2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist雾+阴天，雾+碎云、雾+少云、雾3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds小雪、小雨+雷暴+散云，小雨+云4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog暴雨+冰雹+雷暴+雾，雪+雾temp(温度) - temperature in Celsiusatemp(体感温度) - "feels like" temperature in Celsiushumidity(湿度) - relative humiditywindspeed(风速) - wind speedcasual(临时用户) - number of non-registered user rentals initiatedregistered(注册用户) - number of registered user rentals initiatedcount(总租车数) - number of total rentals'''#获取文件地址def get_file_path(file_name):    PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))    path = os.path.join(PROJECT_ROOT, 'data/bike-sharing-demand/'+file_name)    return pathdef get_data():    PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))    handle_path = os.path.join(PROJECT_ROOT,'data/bike-sharing-demand/handled.csv')    try:        handle_df = pd.read_csv(handle_path)    except IOError:        print('没有处理过的数据，读取原始数据')        train_df = get_orign_df('train')        train_df['is_train'] = 1        test_df = get_orign_df('test')        test_df['is_train'] = 0        handle_df = handle_data(train_df, test_df)        return handle_df    else:        print ('数据已经处理过，直接读取')        handle_df = pd.read_csv(handle_path)        return handle_df#获取原始训练数据def get_orign_df(file_name):    PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))    path = os.path.join(PROJECT_ROOT,'data/bike-sharing-demand/'+file_name+'.csv')    orign_df = pd.read_csv(path)    print (orign_df.info())    print (orign_df.head())    return orign_df#处理数据def handle_data(train_df,test_df):    #1.处理count异常值    df = train_df.copy()    print (df.describe().T)    #这里可以看出count的标准差为181，几乎和平均值191相同了，而且75%分位数为284，最大值却为977，    #由此得出count的波动较大，我们详细看下count的密度分布    # f,ax = plt.subplots(figsize=(10,5))    # sns.distplot(df['count'])    # ax.set_title('Distribution of count')    # plt.show()    # 可以看到，count的密度分部为严重右偏，有一条很长的尾，我们将这个长尾进行处理，去除count的    # 3个标准差以外的数据    train_WithoutOutliers = df[np.abs(df['count']-df['count'].mean()) <= 3*df['count'].std()]    # f,ax = plt.subplots(figsize=(10,5))    # sns.distplot(train_WithoutOutliers['count'])    # ax.set_title('Distribution of count')    # plt.show()    #可以看出比先前稍微好了一点，但是数据波动还是太大，我们希望波动相对更加稳定：    #对数变换可以很好的处理自变量变大，因变量方差也变量的情况，所以我们选择使用对数变换来将数据进行处理    train_WithoutOutliers['count_log'] = np.log(train_WithoutOutliers['count'])    # sns.distplot(train_WithoutOutliers['count_log'])    # plt.title('Distribution of count after log')    # plt.show()    #可以看出，这里数据的波动已经相对 来说比较稳定，这样可以更好的进行后面的模型训练    #2.合并数据及处理    df = train_WithoutOutliers.append(test_df,ignore_index=True)    df = pd.DataFrame(df,columns=train_WithoutOutliers.columns)    print (df.head())    print (df.info())    print (df['registered'].isnull().any())    #看到datetime不是datetime类型，我们将其进行转化    df['datetime'] = pd.to_datetime(df['datetime'],format='%Y-%m-%d %H:%M:%S')    #为便于后面进行特征工程，我们将其转为为时段，年份，月份，星期    df['year'] = df['datetime'].dt.year    df['month'] = df['datetime'].dt.month    df['weekday'] = df['datetime'].dt.weekday    df['hour'] = df['datetime'].dt.hour    print (df.head())    # 查看相关数据的密度曲线    # 可以看到上面的temp / atemp / humidity / windspeed都属于数值类型的数据，我们来看下他们的分布    # f,ax = plt.subplots(2,2,figsize=(15,10))    # sns.distplot(df['temp'],ax=ax[0,0])    # sns.distplot(df['atemp'],ax=ax[0,1])    # sns.distplot(df['humidity'],ax=ax[1,0])    # sns.distplot(df['windspeed'],ax=ax[1,1])    # ax[0,0].set_title('distribution of temp',fontsize=18)    # ax[0,1].set_title('distribution of atemp',fontsize=18)    # ax[1,0].set_title('distribution of humidity',fontsize=18)    # ax[1,1].set_title('distribution of windspeed',fontsize=18)    # plt.subplots_adjust(hspace=.3)    # plt.show()    # 从上面的分布我们可以发现一些问题，风速为0的时候数据很多, 而在1 - 6    # 之间却有很多的缺失值，我们可以推测这些风速为0并不是真的风速为0，而是缺失值，我们使用随机森林来对这些缺失值进行填充    print (df.describe()['windspeed'])    #使用随机森林填补缺失值    from sklearn.ensemble import RandomForestRegressor    # 将风速分为0和非0两部分    windspeed_0 = df[df['windspeed']==0]    windspeed_not0 = df[df['windspeed']!=0]    #选定模型    rf_model = RandomForestRegressor(n_estimators=1000,random_state=42)    #选择特征    windcolumns = ['season', 'weather', 'humidity', 'month', 'temp', 'year', 'atemp']    #训练模型    rf_model = rf_model.fit(windspeed_not0[windcolumns],windspeed_not0['windspeed'])    #模型预测    pred = rf_model.predict(windspeed_0[windcolumns])    windspeed_0.loc[:,'windspeed'] = pred    #链接两部分    df_rfw = windspeed_0.append(windspeed_not0)    df_rfw.reset_index(inplace=True)    df_rfw.drop('index',axis=1,inplace=True)    #再看下密度曲线    f,ax = plt.subplots(2,2,figsize=(15,10))    sns.distplot(df_rfw['temp'],ax=ax[0,0])    sns.distplot(df_rfw['atemp'],ax=ax[0,1])    sns.distplot(df_rfw['humidity'],ax=ax[1,0])    sns.distplot(df_rfw['windspeed'],ax=ax[1,1])    ax[0,0].set_title('distribution of temp',fontsize=18)    ax[0,1].set_title('distribution of atemp',fontsize=18)    ax[1,0].set_title('distribution of humidity',fontsize=18)    ax[1,1].set_title('distribution of windspeed',fontsize=18)    plt.subplots_adjust(hspace=.3)    plt.show()    PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))    path = os.path.join(PROJECT_ROOT,'data/bike-sharing-demand/handled.csv')    df_rfw.to_csv(path,index=False)    print ('数据保存成功')    return df_rfw'''2.3分析数据'''#2.3.1整体观察def analysis_1(data_df):    df = data_df.copy()    #相关系数矩阵    a = df.corr().sort_values('count',ascending=False)    print (a)    f,ax = plt.subplots(figsize=(10,10))    #调色板ma    cmap = sns.diverging_palette(220,10,as_cmap=True)    sns.heatmap(a,ax=ax,square=True,lw=0.3,cmap=cmap,annot=True)    ax.set_title('相关系数矩阵',fontsize=20)    plt.show()    print (a.sort_values('count',ascending=False)['count'])    # 由上面可以看出它们的相关系数排行为    # hour > temp > atemp > year > month > season > windspeed > weekday > holiday    # 而负相关排行为humidity > weather > workingday#2.3.2 逐项展示#2.3.2.1 hour对租赁趋势的影响def analysis_2(data_df):    df = data_df.copy()    print (df['workingday'].value_counts())    #获取非工作日数据    workingday_0 = df[df['workingday']==0].groupby(by='hour')[['casual','registered','count']].mean()    workingday_1 = df[df['workingday']!=0].groupby(by='hour')[['casual','registered','count']].mean()    f,[ax1,ax2] = plt.subplots(1,2,figsize=(15,5))    workingday_0.plot(ax=ax1,style='.-')    workingday_1.plot(ax=ax2,style='.-')    ax1.set(title='非工作日hour与用户租赁数的关系',ylabel='每小时的用户租赁数')    ax2.set(title='工作日hour与用户租赁数的关系', ylabel='每小时的用户租赁数')    #保存图片    path = get_file_path('count_after_hour')    plt.savefig(path,dpi=80)    plt.show()    # 通过对比可知：    # 1.工作日与非工作日的骑车的时间段完全不一样    # 非工作日中：用户用车数量从早上五点到下午一点一直呈增长态势，再由下午一点到第二天凌晨五点呈现下降趋势，总体呈现一个正态分布的趋势。    # 工作日中：早上上班时间和下午下班时间骑车人数较多，在中午有个小小的增长，估计是中午下班的时候骑车出去小范围的吃饭、购物等导致的    # 2.注册会员的用车数量均远远的大于临时用车的数量，估计是会员的优惠要比临时的优惠强，导致办理会员人数较多且使用频率较多导致#2.3.2.2 温度对租赁趋势的影响# temp(温度) - temperature in Celsius# atemp(体感温度) - "feels like" temperature in Celsiusdef analysis_3(data_df):    df = data_df.copy()    result_df = df.groupby(by=['year','month'])[['temp','atemp']].mean()    result_df.plot()    plt.show()    print (result_df)    #这个可以看出，温度大体上都是七月前温度上升，七月后温度下降    temp_df = df.groupby(by='temp')[['casual','registered','count']].mean()    atemp_df = df.groupby(by='atemp')[['casual','registered','count']].mean()    f,[ax1,ax2] = plt.subplots(1,2,figsize=(15,5))    temp_df.plot(ax=ax1,style='.-')    atemp_df.plot(ax=ax2,style='.-')    ax1.set(title='租赁人数与temp的关系')    ax2.set(title='租赁人数与atemp的关系')    #保存图片    path = get_file_path('temp')    plt.savefig(path,dpi=200)    plt.show()# 2.3.2.3湿度对租赁趋势的影响# humidity(湿度) - relative humiditydef analysis_4(data_df):    df = data_df.copy()    temp_df = df.groupby(by=['year','month'])['humidity'].mean()    f,ax = plt.subplots(1,1,figsize=(15,5))    temp_df.plot(ax=ax)    plt.title('湿度随着时间变化趋势')    plt.show()    humidity = df.groupby(by='humidity')[['casual','registered','count']].mean()    humidity.plot()    plt.ylabel('平均每小时租赁人数')    plt.title('湿度与租赁人数的关系')    path = get_file_path('humidity')    plt.savefig(path,dpi=200)    plt.show()    #可以看出湿度20之前租赁人数总体呈上升趋势，湿度20以后总体呈下降趋势#2.3.2.5季节对租赁趋势的影响def analysis_5(data_df):    df = data_df.copy()    df.groupby(by=['year','season'])[['casual','registered','count']].mean().plot()    plt.show()#2.3.2.6天气对租赁趋势的影响# weather(天气) -# 1: Clear, Few clouds, Partly cloudy, Partly cloudy清澈，少云，多云# 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist雾+阴天，雾+碎云、雾+少云、雾# 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds小雪、小雨+雷暴+散云，小雨+云# 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog暴雨+冰雹+雷暴+雾，雪+雾def analysis_5(data_df):    df = data_df.copy()    f,ax = plt.subplots(figsize=(8,5))    df.groupby(by='weather')[['casual','registered','count']].mean().plot(ax=ax,color=['b','g','r'])    ax.set_xticks(range(1,5))    ax.set_xticklabels(range(1,5),[])    ax.set_ylabel('平均每小时租赁数')    ax.set_title('天气与平均每小时租赁数的关系',fontsize=15)    path = get_file_path('weather')    plt.savefig(path,dpi=200)    plt.show()    # 天气等级1 - 4    # 分别表示的天气由好到坏    # 1.    # 我们从上图天气1 - 3    # 可以知道：天气越好，租赁人数越多    #    # 2.    # 天气4是这里最差的天气，非会员的使用量符合预期，租赁人数较少，但是会员的使用人数却比天气等级为3的人要多的多，导致总体租车量产生了一个偏离预期的值，我们把天气等级为4的记录单独拿出来看    print (df[df['weather']==4])    #这里天气等级为4的已有记录只有一条，发生时间在下午6点下班的时候，数据有些异常#2.3.2.7风速对租赁趋势的影响# windspeed(风速) - wind speeddef analysis_6(data_df):    df = data_df.copy()    df.groupby(by=['year','month'])['windspeed'].mean().plot()    plt.show()    array = np.arange(5,65,5)    df['wind_class'] = pd.cut(df['windspeed'],array)    print (array)    df.groupby(by='wind_class')[['casual','registered','count']].mean().plot()    plt.title('风速对租赁数量的影响', fontsize=15)    plt.ylabel('平均每小时的租赁数量')    path = get_file_path('windspeed')    plt.savefig(path,dpi=200)    plt.show()'''2.4 特征工程数值型特征：temp 温度，atemp温度，windspeed风速，humidity湿度分类型特征：season季节，workingday 工作日，holiday 非工作日，weather天气时间型特征：hour小时，weekday星期，month月份，year年份'''def analysis_6(data_df):    df = data_df.copy()    # 我们考虑到temph和atemp的相关系数为0.99，比较相近，将两个特征转化为一个特征    df['temp_mean'] = (df['temp'] + df['atemp']) / 2    #将分类特征进行onehot编码    season_dummy = pd.get_dummies(df['season'],prefix='season')    weather_dummy = pd.get_dummies(df['weather'],prefix='weather')    month_dummy = pd.get_dummies(df['month'],prefix='month')    #合并特征    feature = pd.concat([df[['datetime','is_train','count_log','temp_mean','windspeed','humidity','workingday','holiday','hour','weekday','year']],season_dummy,weather_dummy,month_dummy],axis=1)    print (feature)    print (feature.info())    return feature'''2.5建立模型'''def analysis_7(data_df):    #获得特征数据    feature = analysis_6(data_df)    train_df = feature[feature['is_train']==1]    train_df = train_df.drop(columns=['datetime','is_train'])    train_x = train_df.iloc[:,train_df.columns!='count_log']    train_y = train_df.iloc[:,train_df.columns=='count_log']    test_df = feature[feature['is_train']==0]    test_df = test_df.drop(columns=['datetime','is_train'])    test_x = test_df.iloc[:,test_df.columns!='count_log']    test_y = test_df.iloc[:,test_df.columns=='count_log']    from sklearn.ensemble import RandomForestRegressor    from sklearn.model_selection import cross_val_score    rfc = RandomForestRegressor(n_estimators=850,random_state=420)    #交叉验证    # score = model_test_index.corss_val_score_cus(rfc,train_x,train_y['count_log'],cv=5,scoring='neg_mean_squared_error')    # print (score)  #0.176    rfc.fit(train_x,train_y['count_log'])    pred = rfc.predict(test_x)    # 原来进行了对数变化，现将其变回来    pred_exp = np.exp(pred)    pred_exp = pd.Series(pred_exp,name='count')    print (pred_exp)    result_df = feature[feature['is_train'] == 0]['datetime'].reset_index(drop=True)    result_df = pd.concat([result_df,pred_exp],axis=1).sort_values(by='datetime',ascending=True)    path = get_file_path('predict_concat.csv')    result_df.to_csv(path,index=False)    # score = []    # for i in range(800, 900, 10):    #     print (i)    #     rfc = RandomForestRegressor(n_estimators=i, n_jobs=-1, random_state=420)    #     s = -cross_val_score(rfc, train_x, train_y['count_log'], cv=5,scoring='neg_mean_squared_error').mean()    #     score.append(s)    # print (300 + score.index(min(score)) * 50, min(score))    # plt.figure(figsize=(20, 5))    # plt.plot(range(800, 900, 10), score, color='red')    # plt.show()    # 850    # 0.17386538034077098if __name__ == '__main__':#获取到原始数据    data_df = get_data()    print (data_df.info())    analysis_7(data_df)