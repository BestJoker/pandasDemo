# coding:utf-8import pandas as pdimport numpy as npimport osimport matplotlib.pyplot as pltfrom sklearn.model_selection import train_test_split #这里是引用了交叉验证from sklearn.linear_model import LinearRegression  #线性回归'''#回归模型分析步骤根据预测目标，确定自变量和因变量绘制散点图，确定回归模型类型估计模型参数，建立回归模型对回归模型进行检验利用回归模型进行预测'''#让中文显示正常plt.rcParams['font.sans-serif']=['Microsoft YaHei'] #用来正常显示中文标签字体。Microsoft YaHei 或 SimHeiplt.rcParams['axes.unicode_minus']=False #用来正常显示负号'''简单线性回归'''def unitary_line(examDf,x_columns,y_columns,train_size=0.8):    plt.scatter(examDf[x_columns],examDf[y_columns],color='b',label='Exam Data')    plt.xlabel('Hours')    plt.ylabel('Score')    plt.show()    # 相关系数是用以反映变量之间相关关系密切程度的统计指标。    # r(相关系数) = x和y的协方差/(x的标准差*y的标准差) == cov（x,y）/σx*σy（即person系数）    # 对于相关性强度来说的化有以下的关系：    # 0~0.3 弱相关    # 0.3~0.6  中等程度相关    # 0.6~1  强相关    rDf = examDf.corr()    print (rDf)    # pandas中的数学统计函数D.corr()可以反应数据间的相关性关系，可从表值中反应出学习时间与分数之间的相关性为强相关（0.6~1）。    # 对于简单线性回归来来说，简单回归方程为： y = a + b*x (模型建立最佳拟合线)最佳拟合线也是需要通过最小二乘法来实现其作用。    # 对于OLS即最小二乘法我们需要知道的一个关系为点误差，点误差 = 实际值 - 预测值，    # 而误差平方和（Sum of square error） SSE = Σ（实际值-预测值）^2，    # 最小二乘法就是基于SSE实现，最小二乘法 ： 使得误差平方和最小（最佳拟合）。    # 解释完简单线性回归后进行对训练集和测试集的创建，    # 将会使用train_test_split函数来创建（train_test_split是存在与sklearn中的函数）    #X_train为训练数据标签,X_test为测试数据标签,exam_X为样本特征,exam_y为样本标签，train_size 训练数据占比    X_train,X_test,Y_train,Y_test = train_test_split(examDf[x_columns],examDf[y_columns],train_size=train_size)    print("原始数据特征:", examDf[x_columns].shape,          ",训练数据特征:", X_train.shape,          ",测试数据特征:", X_test.shape)    print("原始数据标签:", examDf[y_columns].shape,          ",训练数据标签:", Y_train.shape,          ",测试数据标签:", Y_test.shape)    #散点图    plt.scatter(X_train,Y_train,color='b',label='train data')    plt.scatter(X_test,Y_test,color='r',label='test data')    plt.legend(loc=2)    plt.xlabel('Hours')    plt.ylabel('Pass')    plt.show()    # 由于训练集随机分配的原因每一次运行的结果（点的分布情况，训练集内的情况，测试集内的情况）不都相同。    # 在创建数据集之后我们需要将训练集放入skleran中的线性回归模型（LinearRegression()）进行训练，    # 使用函数种的.fit函数进行模型的训练操作。    model = LinearRegression()    # 对于模型错误我们需要把我们的训练集进行reshape操作来达到函数所需要的要求    # model.fit(X_train,Y_train)    # reshape如果行数=-1的话可以使我们的数组所改的列数自动按照数组的大小形成新的数组    # 因为model需要二维的数组来进行拟合但是这里只有一个特征所以需要reshape来转换为二维数组    X_train = X_train.values.reshape(-1,1)    X_test = X_test.values.reshape(-1,1)    model.fit(X_train,Y_train)    #在模型训练完成之后会得到所对应的方程式（线性回归方程式）需要利用函数中的intercept_与coef_来得到    a = model.intercept_ #截距    b = model.coef_ #回归系数    print ('最佳拟合线：截距',a,',回归系数：',b)    # 接下来需要对模型进行预测和对模型进行评价，在进行评价之间将会引入一个决定系数r平方的概念。    # 对于决定系数R平方常用于评估模型的精确度。    # 下列为R平方的计算公式：    # ● y误差平方和 = Σ(y实际值 - y预测值) ^ 2    # ● y的总波动 = Σ(y实际值 - y平均值) ^ 2    # ● 有多少百分比的y波动没有被回归拟合线所描述 = SSE / 总波动    # ● 有多少百分比的y波动被回归线描述 = 1 - SSE / 总波动 = 决定系数R平方    # 对于决定系数R平方来说    # （1）回归线拟合程度：有多少百分比的y波动刻印有回归线来描述(x的波动变化)    # （2）值大小：R平方越高，回归模型越精确(取值范围0~1)，1无误差，0无法完成拟合.    # 对于预测来说我们需要运用函数中的model.predict()来得到预测值    # 训练数据的预测值    y_train_pred = model.predict(X_train)    # 绘制最佳拟合线：标签用的是训练数据的预测值y_train_pred    plt.plot(X_train,y_train_pred,color='black',linewidth=3,label='best line')    # 测试数据散点图    plt.scatter(X_test,Y_test,color='red',label='test data')    #训练集    plt.scatter(X_train,Y_train,color='g',label='train data')    plt.show()    #计算你和评分    score = model.score(X_test,Y_test) #回归模型越精确(取值范围0~1)    print (score)#构建数据集examDict = {'学习时间':[0.50,0.75,1.00,1.25,1.50,1.75,1.75,                     2.00,2.25,2.50,2.75,3.00,3.25,3.50,4.00,4.25,4.50,4.75,5.00,5.50],             '分数':[10,22,13,43,20,22,33,50,62,                   48,55,75,62,73,81,76,64,82,90,93]}examDf = pd.DataFrame(examDict)print (examDf)#调用一元线性回归unitary_line(examDf,x_columns=['学习时间'],y_columns=['分数'])PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))path = os.path.join(PROJECT_ROOT,'data/数据汇总.xlsx')#创建一个集合，存放所有的数据total_df = pd.DataFrame()date_array = ['2019-04','2019-05','2019-07','2019-08','2019-10','2020-01']for date in date_array:    print (date)    df = pd.read_excel(path, sheet_name='2019-05')    df['play_time'] = df['play_time'] / 60 #变成小时    df['日期'] = date    total_df = total_df.append(df)    print (df.head(3))#获得所有的数据集合print (total_df.head(3))print (total_df.info())'''PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))path = os.path.join(PROJECT_ROOT,'data/多元回归数据集.xlsx')orign_data = pd.read_excel(path)print (orign_data)def build_lr(orign_data):    X = orign_data[['百分比利率','抽取用户佣金']]    y = orign_data[['金融产品销售额']]    # 利用sklearn里面的包来对数据集进行划分，以此来创建训练集和测试集    # train_size表示训练集所占总数据集的比例    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=532)#选择20%为测试集    print ('训练集测试及参数')    print('X_train.shape={}\n y_train.shape ={}\n X_test.shape={}\n,  y_test.shape={}'.format(X_train.shape,                                                                                              y_train.shape,                                                                                              X_test.shape,                                                                                              y_test.shape))    linreg = LinearRegression()    #训练    model = linreg.fit(X_train,y_train)    print ('模型参数:')    print (model)    #训练后模型截距    print ('模型截距:')    print (linreg.intercept_)    #训练后模型权重（特征个数无变化），回归系数    print ('参数权重:')    print (linreg.coef_)    y_pred = linreg.predict(X_test)    sum_mean = 0    for i in range(len(y_pred)):        sum_mean += (y_pred[i] - y_test.values[i]) ** 2    sum_erro = np.sqrt(sum_mean / len(y_pred))    # 评价    # (1) 评价测度    # 对于分类问题，评价测度是准确率，但这种方法不适用于回归问题。我们使用针对连续数值的评价测度(evaluation metrics)。    # 这里介绍3种常用的针对线性回归的测度。    # 1)平均绝对误差(Mean Absolute Error, MAE)    # (2)均方误差(Mean Squared Error, MSE)    # (3)均方根误差(Root Mean Squared Error, RMSE)    # 这里我使用RMES。    #calculate RMSE，均方根误差    print ('RMSE by hand：',sum_erro)    #做ROC曲线    plt.figure()    plt.plot(range(len(y_pred)),y_pred,'b',label='predict')    plt.plot(range(len(y_pred)),y_test,'r',label='test')    plt.legend(loc='upper right') #显示图中的标签    plt.xlabel('金融产品销售额')    plt.ylabel('value of sales')    plt.show()    # R方检测    # 决定系数r平方    # 对于评估模型的精确度    # y误差平方和 = Σ(y实际值 - y预测值)^2    # y的总波动 = Σ(y实际值 - y平均值)^2    # 有多少百分比的y波动没有被回归拟合线所描述 = SSE/总波动    # 有多少百分比的y波动被回归线描述 = 1 - SSE/总波动 = 决定系数R平方    # 对于决定系数R平方来说1） 回归线拟合程度：有多少百分比的y波动刻印有回归线来描述(x的波动变化)    score =linreg.score(X_test,y_test)    print (score)build_lr(orign_data)'''