# coding:utf-8import pandas as pdimport numpy as npimport osimport matplotlib.pyplot as pltimport seaborn as snsimport warningswarnings.filterwarnings('ignore')pd.options.mode.chained_assignment = None # 默认是'warn'plt.rcParams['font.sans-serif']=['Microsoft YaHei'] #用来正常显示中文标签字体。Microsoft YaHei 或 SimHeiplt.rcParams['axes.unicode_minus']=False #用来正常显示负号PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))path = os.path.join(PROJECT_ROOT,'data/HR_comma_sep.csv')orign_df = pd.read_csv(path)print (orign_df.head())print (orign_df.info())#解决df看不全的问题print (orign_df.describe())# 观测异常值# 结论： 除了工作年限外, 其他均无异常值。该异常值也反映了该公司员工中以年轻人为主def abnormal_value(df):    temp_df = df.copy()    fig,ax = plt.subplots(1,5,figsize=(12,2))    for i in range(0,5):        print (i)        sns.boxplot(x=temp_df.columns[i], data=temp_df, ax=ax[i])    plt.show()# abnormal_value(orign_df)'''left：是否离职satisfaction_level：满意度last_evaluation：绩效评估number_project：完成项目数average_montly_hours：平均每月工作时间time_spend_company：为公司服务的年限work_accident：是否有工作事故promotion：过去5 年是否有升职salary：薪资水平1.人力资源总体情况'''def total_state(df):    temp_df = df.copy()    data = temp_df['left'].value_counts()    print (data)    fig = plt.figure(figsize=(10,10),dpi=80)    plt.pie(data,labels=data.index,startangle = 90,autopct='%1.1f%%')    plt.axis('square')    plt.legend()    plt.show()# total_state(orign_df)'''是否离职与其余9个因素的关系'''# 2.1 对公司满意度与是否离职的关系def left_and_satisfaction_level(df,target):    temp_df = df.copy()    fig = plt.figure(figsize=(12,8),dpi=80)    sns.boxplot(x='left',y=target,data=temp_df,width=0.4)    plt.legend()    plt.xlabel('left')    plt.ylabel(target)    plt.title('对公司满意度')    plt.show()# left_and_satisfaction_level(orign_df,'satisfaction_level')# 结论： 就中位数而言, 离职人员对公司满意度相对较低, 且离职人员对公司满意度整体波动较大.# 另外离职人员中没有满意度为1的评价.# 2.2 最新考核评估与是否离职的关系def left_and_last_evaluation(df):    temp_df = df.copy()    temp_df['last_evaluation'] = pd.cut(temp_df['last_evaluation'],5,labels=['低','中低','中','中高','高'])    temp_df_1 = temp_df[temp_df['left']==1]['last_evaluation'].value_counts().to_frame()    temp_df_1['rate'] = temp_df_1['last_evaluation'] / temp_df_1['last_evaluation'].sum()    print (temp_df_1)    temp_df_0 = temp_df[temp_df['left']==0]['last_evaluation'].value_counts().to_frame()    temp_df_0['rate'] = temp_df_0['last_evaluation'] / temp_df_0['last_evaluation'].sum()    print (temp_df_0)    fig = plt.figure(figsize=(12,10),dpi=80)    sns.lineplot(temp_df_1.index,temp_df_1['rate'],color='r',label='离职')    sns.lineplot(temp_df_0.index,temp_df_0['rate'],color='b',label='在职')    plt.legend()    plt.title('最新考核评估与是否离职的关系')    plt.show()# left_and_last_evaluation(orign_df)# 结论：考核评价偏低或偏高的员工更容易离职。在职人员的最新考核评价较为平均，# 大多数分布在中低-高之间。离职员工的最新考核评价集中在中低和高两个段。# 2.3 所参加项目数与是否离职的关系def left_and_number_project(df):    temp_df = df.copy()    temp_df = temp_df.groupby(by=['number_project','left'])['salary'].count().unstack()    df_level = temp_df.apply(lambda x:x/x.sum(),axis=1)    df_level.plot.bar(stacked=True,figsize=(14,6))    plt.title('所参加项目数与是否离职的关系')    plt.show()    print (temp_df['number_project'].value_counts().to_frame())    pie_df = temp_df['number_project'].value_counts().to_frame()    plt.pie(pie_df.values,labels=pie_df.index,startangle=90,autopct='%1.1f%%')    plt.title('不同项目员工参与人数和占比')    plt.legend()    plt.show()# left_and_number_project(orign_df)# 2.4 平均每月工作时长与是否离职的关系def left_and_average_montly_hours(df):    temp_df = df.copy()    hours_left_table = pd.crosstab(index=temp_df['average_montly_hours'],columns=temp_df['left'])    print (hours_left_table.head())    no_left = sns.kdeplot(temp_df.loc[temp_df['left']==0,'average_montly_hours'],color='b',shade=True,label='no left')    left = sns.kdeplot(temp_df.loc[temp_df['left']==1,'average_montly_hours'],color='r',shade=True,label='left')    plt.show()# left_and_average_montly_hours(orign_df)# 结论： 离职员工的平均每月工作时长集中在(125,165]小时和(215,285]小时之间，而在职员工平均每月工作时长分布均匀，# 说明平均每月工作时长太短（日均6-7.5h）或太长(日均10h以上)，都可能导致员工离职。将员工月平均工作时长调整在(155,235]之间，# 2.5 满意度等级和是否离职的关系def left_and_satisfaction_level(df):    temp_df = df.copy()    satis_left_table = pd.crosstab(index=temp_df['satisfaction_level'],columns=temp_df['left'])    fig = plt.figure(figsize=(10,5))    no_left = sns.kdeplot(temp_df.loc[temp_df['left']==0,'satisfaction_level'],color='b',shade=True,label='no left')    left = sns.kdeplot(temp_df.loc[temp_df['left']==1,'satisfaction_level'],color='r',shade=True,label='left')    plt.show()# left_and_satisfaction_level(orign_df)# 2.6 平均工作年限与是否离职的关系def left_and_time_spend_company(df):    temp_df = df.copy()    company_left_table = pd.crosstab(index=temp_df['time_spend_company'],columns=temp_df['left'])    company_left_table.plot(kind='bar',figsize=(5,5),stacked=True)    plt.show()    temp_df.loc[temp_df['left']==1,'time_spend_company'].plot(kind='hist',normed=1,bins=10,stacked=False,alpha=1)    plt.title('离职员工工作年限分布')    plt.show()left_and_time_spend_company(orign_df)# 2.7 绩效评估和是否离职的关系def left_and_last_evaluation(df):    temp_df = df.copy()    evaluation_left_table = pd.crosstab(index=temp_df['last_evaluation'],columns=temp_df['left'])    print (evaluation_left_table.head())    fig = plt.figure(figsize=(10,5))    no_left = sns.kdeplot(temp_df.loc[temp_df['left']==0,'last_evaluation'],color='b',shade=True,label='no left')    left = sns.kdeplot(temp_df.loc[temp_df['left']==1,'last_evaluation'],color='r',shade=True,label='left')    plt.show()# left_and_last_evaluation(orign_df)# 2.8 绩效评估和满意度def left_and_last_evaluation_and_satisfaction_level(df):    temp_df = df.copy()    df1 = temp_df[temp_df['left']==1]    fig,ax = plt.subplots(figsize=(10,10))    pd.plotting.scatter_matrix(df1[['satisfaction_level','last_evaluation']],color='k',ax=ax)    plt.show()# left_and_last_evaluation_and_satisfaction_level(orign_df)'''二、探索影响员工离职的驱动力分析'''from sklearn.model_selection import train_test_split# 1. 优秀员工离职驱动力分析# 首先我们定义优秀员工：最新考核评估>=0.8 | 参加项目数>=5 | 平均每月工作时长>=230小时# 为了尽可能将各个职务，各个工作年限的员工包括进来，三个条件满足任一条件即可def excellent_employees_analysis(df):    temp_df = df.copy()    excellent_df = temp_df[(temp_df['last_evaluation']>=0.8) | (temp_df['number_project']>=5) | (temp_df['average_montly_hours']>=230)                 |(temp_df['time_spend_company']>=4)]    print (excellent_df.head())    print (excellent_df.info())    #获取数据    dtree_df = excellent_df.copy()    # 哑变量转换    dtree_df = pd.get_dummies(data=dtree_df,columns=['sales','salary'],drop_first=False)    print (dtree_df.head())    print (dtree_df.info())    #切分自变量和因变量    X = dtree_df.drop(['left'],axis=1)    y = dtree_df['left']    return X,yX,y = excellent_employees_analysis(orign_df)from sklearn.ensemble import RandomForestClassifierfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.model_selection import GridSearchCV  #网格搜索import model_test_indeximport osimport math# 1.1 决策树def decisionTree(X,y):    os.environ["PATH"] += os.pathsep + 'G:/program_files/graphviz/bin'    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=1)    #超参数选择：考虑到离职人数占比少，存在样本不均衡的现象，故选择class_weight = ‘balanced’，改善样本不均衡带来的预测偏差。    #调参    # scores = []    # for i in range(0,15):    #     print (i)    #     clf = DecisionTreeClassifier(max_depth=i+1, random_state=0,    #                                  class_weight='balanced')    #     clf.fit(X_train,Y_train)    #     scores.append(clf.score(X_test,Y_test))    # print ([*zip(range(0, 15),scores)])    # plt.plot(range(0, 15), scores, color='red', label='max_depth')    # plt.legend()    # plt.show()    #结论：max_depth = 5 或 7    #1.1决策树    clf = DecisionTreeClassifier(max_depth=5,min_samples_leaf=math.ceil(X.shape[0]*0.07),random_state=0,class_weight = 'balanced')    clf = clf.fit(X_train,Y_train)    #查看系数重要程度    result_c_df = pd.DataFrame([*zip(X_train.columns,clf.feature_importances_)],columns=['feature','c'])    result_c_df = result_c_df.sort_values(by='c',ascending=False).reset_index()    print (result_c_df)    print (clf.score(X_test,Y_test))    y_pred = clf.predict(X_test)    #绘制基础数据和混淆矩阵    model_test_index.basic_data_confusion(Y_test,y_pred)    #交叉验证    model_test_index.corss_val_score_cus(clf,X,y,cv=5)    # 结果分析：真实要离职的611人中，预测对了539人，召回率为88.22 %；    # 预测结果显示要离职的924人中，预测对了的为539人，精确率为58.33 %。    # 如果后续需要根据预测结果进行访谈，这样的预测结果会大大增加资源投入，模型效果仍有待改进。# decisionTree(X,y)# 1.2 随机森林def randomForest(X,y):    # 超参数选择 ：因数据类别数量差别很大，使用class_weight = 'balanced’来做平衡，其他使用默认值,查看随机森林分类结果    rfc = RandomForestClassifier(oob_score=True,random_state=10,class_weight='balanced')    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=1)    rfc.fit(X_train,Y_train)    y_predcit = rfc.predict(X_test)    model_test_index.basic_data_confusion(Y_test,y_predcit)    # 决策树模型准确率: 98.59 %    # 决策树模型精确率: 98.80 %    # 决策树模型召回率: 93.94 %    # 决策树模型F1值: 96.31 %    # AUC值为： 98.71 %    y_predprob = rfc.predict_proba(X_test)    model_test_index.auc_roc_curve(Y_test,y_predprob)    # model_test_index.corss_val_score_cus(rfc,X,y,cv=10)    # 结果分析：真实要离职的611人中，预测对了572人，召回率为93.62 %；    # 预测结果显示要离职的578人中，预测对了的为572人，精确率为98.96 %。    # 相比决策树模型，大大提高了预测的精确度，召回率也由88.22 % 提升至93.62 %，故，随机森林模型预测效果更好。    #影响员工离职的主要因素    y_importances = rfc.feature_importances_    x_importances = X_train.columns.values    y_pos = np.arange(len(x_importances))    #横向柱状图    plt.figure(figsize=(10,8))    sns.barplot(y=x_importances,x=y_importances,orient='h')    plt.yticks(y_pos,x_importances)    plt.xlabel('Importances')    plt.xlim(0,0.3)    plt.title('Features Importances')    plt.show()    #主要因素倒叙排列    result_c_df = pd.DataFrame([*zip(x_importances,y_importances)],columns=['feature','c'])    result_c_df = result_c_df.sort_values(by='c',ascending=False).reset_index(drop=True)    print (result_c_df)# randomForest(X,y)# 结论： 结果和决策树模型基本相同。影响员工离职的主要因素为，工作年限、员工满意度、月平均工作时长、最近一次评估结果、参与项目数量。#                feature         c# 0      time_spend_company  0.292427# 1      satisfaction_level  0.204447# 2    average_montly_hours  0.183350# 3         last_evaluation  0.141367# 4          number_project  0.105368# 5           Work_accident  0.015155#高斯贝叶斯def gaussian_nb(X,y):    from sklearn.naive_bayes import GaussianNB    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=1)    gnb = GaussianNB()    gnb.fit(X_train,Y_train)    y_predcit = gnb.predict(X_test)    model_test_index.basic_data_confusion(Y_test,y_predcit)    # 决策树模型准确率: 83.32 %    # 决策树模型精确率: 55.08 %    # 决策树模型召回率: 81.67 %    # 决策树模型F1值: 65.79 %    y_predprob = gnb.predict_proba(X_test)    model_test_index.auc_roc_curve(Y_test,y_predprob)    # AUC值为： 89.36 %    model_test_index.corss_val_score_cus(gnb,X,y,cv=5)# gaussian_nb(X,y)#SVM模型def svm_cus(X,y):    from sklearn.svm import SVC    from sklearn.preprocessing import StandardScaler    from sklearn.model_selection import StratifiedShuffleSplit #?    from sklearn.model_selection import GridSearchCV    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=1)    scaler = StandardScaler()    X_train_scale = scaler.fit_transform(X_train)    X_test_scale = scaler.fit_transform(X_test)    # Kernel = ['linear', 'poly', 'rbf', 'sigmoid']    # for kernel in Kernel:    #     print (kernel)    #     clf = SVC(kernel=kernel    #               , gamma='auto'    #               , degree=1    #               , cache_size=5000  # 使用多少内存来处理数据，单位MB    #               ).fit(X_train_scale, y_train)    #     print ('The accuracy under kernel %s is %f' % (kernel, clf.score(X_test_scale, y_test)))    #找到'rbf'模式最好    clf = SVC(kernel='rbf',gamma=0.9665809768637532,degree=1,cache_size=5000,probability=True)    clf.fit(X_train_scale,Y_train)    y_predcit = clf.predict(X_test_scale)    model_test_index.basic_data_confusion(Y_test,y_predcit)    # 模型准确率: 96.75 %    # 模型精确率: 96.88 %    # 模型召回率: 86.25 %    # 模型F1值: 91.26 %    y_predprob = clf.predict_proba(X_test_scale)    model_test_index.auc_roc_curve(Y_test,y_predprob)    # AUC值为： 97.44%    #网格搜索 最佳参数    # C_range = np.logspace(-3,3,7)    # gamma_range = np.logspace(-3,3,7)    # param_grid = dict(gamma=gamma_range,C=C_range)    # cv = StratifiedShuffleSplit(n_splits=1,test_size=0.3,random_state=42)    # grid = GridSearchCV(SVC(),param_grid=param_grid,cv=cv)    # grid.fit(X_train_scale,Y_train)    # print("The best parameters are %s with a score of %0.2f"    #       % (grid.best_params_, grid.best_score_))    # scores = grid.cv_results_['mean_test_score'].reshape(len(C_range), len(gamma_range))    # print (scores)    # The best parameters are {'C': 100.0, 'gamma': 1.0} with a score of 0.98    print ('-'*40)    #最佳参数    clf = SVC(kernel='rbf',C=100,gamma=1,degree=1,cache_size=5000,probability=True)    clf.fit(X_train_scale,Y_train)    y_predcit = clf.predict(X_test_scale)    model_test_index.basic_data_confusion(Y_test,y_predcit)    # 模型准确率: 96.82 %    # 模型精确率: 93.69 %    # 模型召回率: 89.85 %    # 模型F1值: 91.73 %    y_predprob = clf.predict_proba(X_test_scale)    model_test_index.auc_roc_curve(Y_test,y_predprob)    # AUC值为： 97.40%svm_cus(X,y)'''比较之后，随机森林和SVM效果最好，随机森林更好一些。'''