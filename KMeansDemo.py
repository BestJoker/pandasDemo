# coding:utf-8import pandas as pdimport numpy as npimport osimport matplotlib.pyplot as pltfrom sklearn import preprocessingfrom sklearn.datasets import make_blobsfrom sklearn.datasets import make_classificationfrom sklearn import metricsfrom sklearn.cluster import KMeans#让中文显示正常plt.rcParams['font.sans-serif']=['Microsoft YaHei'] #用来正常显示中文标签字体。Microsoft YaHei 或 SimHeiplt.rcParams['axes.unicode_minus']=False #用来正常显示负号PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))path = os.path.join(PROJECT_ROOT,'data/nba_2013.csv')nba = pd.read_csv(path)print (nba.head())print (nba.info())'''训练数据进行标准化/归一化/正则化，为什么呢？1）去除量纲的影响，将有量纲的数值变成无量纲的纯数值；2）是去除各特征之间数值差异过大的问题，比如一个向量（uv:10000, rate:0.03,money: 20)，如果要与其它向量一起计算欧氏距离或者余弦相似度时，会向uv倾斜非常严重，导致其余2个特征对模型的贡献度非常低3）提升训练的速度，防止过拟合n_samples:待生成的样本的总数n_features:每个样本的特征数,默认为2centers: 要生成的样本中心（类别）数，默认为3cluster_std: 每个类别的方差，默认为1shuffle: 打乱 (default=True)sklearn1)n_clusters: K值，这个值一般需要结合第3点的评判标准，找到最佳的K2）max_iter： 最大的迭代次数，一般如果是凸数据集的话可以不管这个值，如果数据集不是凸的，可能很难收敛，此时可以指定最大的迭代次数让算法可以及时退出循环。3）n_init：用不同的初始化质心运行算法的次数。由于K-Means是结果受初始值影响的局部最优的迭代算法，因此需要多跑几次以选择一个较好的聚类效果，默认是10，一般不需要改。如果你的k值较大，则可以适当增大这个值。4）init： 初始值选择的方式，一般默认’k-means++’。'''#读入数据，提取控球后卫球员，新增特征列：ppg（每场得分），atr（助攻失误率）#使用scatter查看分布情况。#Data preparingpoint_guards=nba[nba['pos']=="PG"]print (point_guards.head())#Calculate Points Per Gamepoint_guards['ppg'] = point_guards['pts'] / point_guards['g']# Sanity check, make sure ppg = pts/gprint (point_guards[['pts', 'g', 'ppg']].head(5))#Calculate Assist Turnover Ratiopoint_guards = point_guards[point_guards['tov'] != 0]point_guards['atr']=point_guards['ast']/point_guards['tov']#Visualize dataplt.scatter(point_guards['ppg'],point_guards['atr'],c='y')plt.title('Point Guards')plt.xlabel('Points Per Game',fontsize=13)plt.ylabel('Assist Turnover Ratio', fontsize=13)plt.show()#x为对应两个参数的listdef searchBestK(df):    model = preprocessing.StandardScaler()    x = model.fit_transform(df)    ch_score = []    ss_score = []    inertia = []    for k in range(2,10):        clf = KMeans(n_clusters=k,max_iter=1000)        pred = clf.fit_predict(x)        ch = metrics.calinski_harabaz_score(x,pred)        ss = metrics.silhouette_score(x,pred)        ch_score.append(ch)        ss_score.append(ss)        inertia.append(clf.inertia_)    fig = plt.figure(figsize=(10,5))    ax1 = fig.add_subplot(131)    plt.plot(list(range(2,10)),ch_score,label='ch',c='y')    plt.title('CH')    plt.legend()    ax2 = fig.add_subplot(132)    plt.plot(list(range(2,10)),ss_score,label='ss',c='b')    plt.title('SS')    plt.legend()    ax3 = fig.add_subplot(133)    plt.plot(list(range(2,10)),inertia,label='inertia',c='g')    plt.title('Inertia')    plt.legend()    plt.show()def cluster(k,df):    model = preprocessing.StandardScaler()    x = model.fit_transform(df)    clf = KMeans(n_clusters=k, max_iter=1000)    pred = clf.fit_predict(x)    plt.scatter(x[:, 0], x[:, 1], c=pred)    plt.title('Kmeans分%s类' %k)    plt.show()#2.算法实现df = point_guards[['ppg', 'atr']]searchBestK(df)cluster(5,df)