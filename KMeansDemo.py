# coding:utf-8import pandas as pdimport numpy as npimport osimport matplotlib.pyplot as pltfrom sklearn import preprocessingfrom sklearn.datasets import make_blobsfrom sklearn.datasets import make_classificationfrom sklearn import metricsfrom sklearn.cluster import KMeans#让中文显示正常plt.rcParams['font.sans-serif']=['Microsoft YaHei'] #用来正常显示中文标签字体。Microsoft YaHei 或 SimHeiplt.rcParams['axes.unicode_minus']=False #用来正常显示负号PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))path = os.path.join(PROJECT_ROOT,'data/kmeans测试.csv')orign_data = pd.read_csv(path,encoding='gbk')print (orign_data.head())print (orign_data.info())'''训练数据进行标准化/归一化/正则化，为什么呢？1）去除量纲的影响，将有量纲的数值变成无量纲的纯数值；2）是去除各特征之间数值差异过大的问题，比如一个向量（uv:10000, rate:0.03,money: 20)，如果要与其它向量一起计算欧氏距离或者余弦相似度时，会向uv倾斜非常严重，导致其余2个特征对模型的贡献度非常低3）提升训练的速度，防止过拟合n_samples:待生成的样本的总数n_features:每个样本的特征数,默认为2centers: 要生成的样本中心（类别）数，默认为3cluster_std: 每个类别的方差，默认为1shuffle: 打乱 (default=True)sklearn1)n_clusters: K值，这个值一般需要结合第3点的评判标准，找到最佳的K2）max_iter： 最大的迭代次数，一般如果是凸数据集的话可以不管这个值，如果数据集不是凸的，可能很难收敛，此时可以指定最大的迭代次数让算法可以及时退出循环。3）n_init：用不同的初始化质心运行算法的次数。由于K-Means是结果受初始值影响的局部最优的迭代算法，因此需要多跑几次以选择一个较好的聚类效果，默认是10，一般不需要改。如果你的k值较大，则可以适当增大这个值。4）init： 初始值选择的方式，一般默认’k-means++’。'''#x为对应两个参数的listdef searchBestK(df):    model = preprocessing.StandardScaler()    x = model.fit_transform(df)    ch_score = []    ss_score = []    inertia = []    for k in range(2,10):        clf = KMeans(n_clusters=k,max_iter=1000)        pred = clf.fit_predict(x)        ch = metrics.calinski_harabaz_score(x,pred)        ss = metrics.silhouette_score(x,pred)        ch_score.append(ch)        ss_score.append(ss)        inertia.append(clf.inertia_)    fig = plt.figure(figsize=(10,5))    ax1 = fig.add_subplot(131)    plt.plot(list(range(2,10)),ch_score,label='ch',c='y')    plt.title('CH')    plt.legend()    ax2 = fig.add_subplot(132)    plt.plot(list(range(2,10)),ss_score,label='ss',c='b')    plt.title('SS')    plt.legend()    ax3 = fig.add_subplot(133)    plt.plot(list(range(2,10)),inertia,label='inertia',c='g')    plt.title('Inertia')    plt.legend()    plt.show()def cluster(k,df):    model = preprocessing.StandardScaler()    x = model.fit_transform(df)    print (x)    clf = KMeans(n_clusters=k, max_iter=1000)    pred = clf.fit_predict(x)    plt.scatter(x[:, 0], x[:, 1], c=pred)    plt.title('Kmeans分%s类' %k)    plt.show()    return preddf = orign_data[['2019年国际排名','2018世界杯','2015亚洲杯']]searchBestK(df)pred = cluster(4,df)result = pd.concat([orign_data,pd.DataFrame(pred)],axis=1)result.rename(columns={0:'聚类'},inplace=True)print (result)