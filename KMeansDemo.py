# coding:utf-8import pandas as pdimport numpy as npimport osfrom sklearn import preprocessingfrom sklearn.datasets import make_blobsfrom sklearn.datasets import make_classificationimport matplotlib.pyplot as plt'''训练数据进行标准化/归一化/正则化，为什么呢？1）去除量纲的影响，将有量纲的数值变成无量纲的纯数值；2）是去除各特征之间数值差异过大的问题，比如一个向量（uv:10000, rate:0.03,money: 20)，如果要与其它向量一起计算欧氏距离或者余弦相似度时，会向uv倾斜非常严重，导致其余2个特征对模型的贡献度非常低3）提升训练的速度，防止过拟合'''PROJECT_ROOT = os.path.dirname(os.path.realpath(__file__))path = os.path.join(PROJECT_ROOT,'02-26围观.xlsx')df = pd.read_excel(path)print (df)'''一、Make_blobs(聚类生成器）n_samples:待生成的样本的总数n_features:每个样本的特征数,默认为2centers: 要生成的样本中心（类别）数，默认为3cluster_std: 每个类别的方差，默认为1shuffle: 打乱 (default=True)'''# f,axes = plt.subplots(2,2,figsize=(10,5))# data1,target1 = make_blobs(n_samples=1000,n_features=2,random_state=0) # random_state是随机数种子，便于复现# data2,target2 = make_blobs(n_samples=1000,n_features=2,random_state=0,centers=4,cluster_std=[0.2,0.5,0.6,0.8]) ## centers是类数量，默认为3# data3,target3 = make_blobs(n_samples=1000,n_features=2,shuffle=True,centers=5,cluster_std=1.2) #cluster_std是标准差，可以设置一样，或每个类设置一个# data4,target4 = make_blobs(n_samples=1000,n_features=2,shuffle=False,random_state=2,centers=5,cluster_std=1.2) # shuffle是可以打乱# axes[0,0].scatter(data1[:,0],data1[:,1],c=target1)# axes[0,1].scatter(data2[:,0],data2[:,1],c=target2)# axes[1,0].scatter(data3[:,0],data3[:,1],c=target3)# axes[1,1].scatter(data4[:,0],data4[:,1],c=target4)# plt.show()'''二、Make_classification(分类生成器）n_features :特征个数= n_informative（） + n_redundant + n_repeatedn_informative：多信息特征的个数n_redundant：冗余信息，informative特征的随机线性组合n_repeated ：重复信息，随机提取n_informative和n_redundant 特征n_classes：分类类别n_clusters_per_class ：某一个类别是由几个cluster构成的'''# data1,target1 = make_classification(n_samples=100,n_features=2,n_informative=1,n_redundant=0,n_repeated=0,n_clusters_per_class=1)# data2,target2 = make_classification(n_samples=100,n_features=2,n_informative=1,n_redundant=0,n_repeated=1,n_clusters_per_class=1)# data3,target3 = make_classification(n_samples=200,n_features=2,n_informative=2,n_redundant=0,n_repeated=0,n_clusters_per_class=1)## f,axes = plt.subplots(1,3,figsize=(10,5))# axes[0].scatter(data1[:,0],data1[:,1],c=target1)# axes[1].scatter(data2[:,0],data2[:,1],c=target2)# axes[2].scatter(data3[:,0],data3[:,1],c=target3)# plt.show()